{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aaca', 'sdedb', 'asdsac']\n",
      "asdsac\n"
     ]
    }
   ],
   "source": [
    "## Exemplo de manejo de lista de listas\n",
    "\n",
    "_ = [[1,2,3],['aaca','sdedb','asdsac'],[9,3,5]]\n",
    "print(_[1])\n",
    "print(_[1][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificador utilizando Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O bloco abaixo só compara tamanho de arquivos para ter certeza de que existe um número igual de listas de keywords e targets.\n",
    "\n",
    "fileHandle = open('train_news_positive_results.txt','r')\n",
    "train_positive = fileHandle.readlines()\n",
    "fileHandle.close()\n",
    "with open('target_positive.txt', 'w') as f:\n",
    "    for item in train_positive:\n",
    "        f.write(\"%s\\n\" % '1')\n",
    "    f.close()\n",
    "\n",
    "fileHandle = open('train_news_negative_results.txt','r')\n",
    "train_negative = fileHandle.readlines()\n",
    "fileHandle.close()\n",
    "with open('target_negative.txt', 'w') as f:\n",
    "    for item in train_negative:\n",
    "        f.write(\"%s\\n\" % '0')\n",
    "    f.close()\n",
    "    \n",
    "fileHandle = open('train_news_positive_results.txt','r')\n",
    "A = fileHandle.readlines()\n",
    "fileHandle.close()\n",
    "fileHandle = open('target_positive.txt','r')\n",
    "B = fileHandle.readlines()\n",
    "fileHandle.close()\n",
    "\n",
    "print(len(A) == len(B))\n",
    "\n",
    "fileHandle = open('train_news_negative_results.txt','r')\n",
    "A = fileHandle.readlines()\n",
    "fileHandle.close()\n",
    "\n",
    "fileHandle = open('target_negative.txt','r')\n",
    "B = fileHandle.readlines()\n",
    "fileHandle.close()\n",
    "\n",
    "print(len(A) == len(B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para Naive Bayes, podemos utilizar duas modalidades de algorítmo:\n",
    "- Multinomial Naive Bayes\n",
    "- Bernoulli Naive Bayes\n",
    "É recomendado que testemos ambas as possibilidades para garantir o melhor encaixe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O número de sites analisados está igual ao número de resultados! Ótimo!\n"
     ]
    }
   ],
   "source": [
    "fileHandle = open('kw_list_train.txt','r')\n",
    "kw_train = fileHandle.readlines()\n",
    "fileHandle.close()\n",
    "\n",
    "fileHandle = open('target_train.txt','r')\n",
    "target_train = fileHandle.readlines()\n",
    "fileHandle.close()\n",
    "\n",
    "if (len(kw_train) == len(target_train)):\n",
    "    print(\"O número de sites analisados está igual ao número de resultados! Ótimo!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precisei criar esta função abaixo para rearranjar o documento com a lista de listas de keywords para separar o resultado de cada website. A função resulta em uma lista consultável de 2 dimensões."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['preso', 'áudios', 'aragarças', 'família', 'tiros', 'jovem', 'suposta', 'pms', 'jeferson', 'troca', 'morreu', 'menino', 'polícia', 'apontam', 'carro']\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "kw_trainA = []\n",
    "for line in kw_train:\n",
    "    sublist = []\n",
    "    line = line.split(\",\")\n",
    "    for word in line:\n",
    "        word = word.rstrip()\n",
    "        word = word.strip(\" ' \\\" \\] \\[ \") # tira aspas, colchetes e espaços\n",
    "        sublist.append(word)\n",
    "    sublist = str(sublist)\n",
    "    kw_trainA.append(sublist)\n",
    "\n",
    "targetA = []\n",
    "for line in target_train:\n",
    "    line = line.rstrip()\n",
    "    targetA.append(line)\n",
    "    \n",
    "print(kw_trainA[1])\n",
    "print(type(kw_trainA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'KW': kw_trainA, 'TARGET': targetA}\n",
    "news_df = pd.DataFrame(data, columns=['KW','TARGET'])\n",
    "#news_df = news_df['KEYWORDS'].append(kw_trainA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KW</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>['provoca', 'foto', 'instagram', 'posta', 'hen...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>['assassinado', 'santos', 'edísio', 'descarta'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>['morto', 'caldas', 'tiros', 'jovem', 'residên...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>['adolescente', 'tráfico', 'araçatuba', 'homem...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>['rosto', 'morto', 'pública', 'tiros', 'idoso'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>['acusado', 'matar', 'suspeito', 'disparo', 'd...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>['arremessar', 'armas', 'seres', 'homens', 'te...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>['disparos', 'morto', 'crime', 'acionada', 'vi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>['preso', 'tupã', 'porta', 'relacionamento', '...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>['pm', 'clonada', 'casa', 'filho', 'armas', 'm...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    KW TARGET\n",
       "136  ['provoca', 'foto', 'instagram', 'posta', 'hen...      0\n",
       "19   ['assassinado', 'santos', 'edísio', 'descarta'...      1\n",
       "75   ['morto', 'caldas', 'tiros', 'jovem', 'residên...      1\n",
       "69   ['adolescente', 'tráfico', 'araçatuba', 'homem...      1\n",
       "27   ['rosto', 'morto', 'pública', 'tiros', 'idoso'...      1\n",
       "62   ['acusado', 'matar', 'suspeito', 'disparo', 'd...      1\n",
       "134  ['arremessar', 'armas', 'seres', 'homens', 'te...      0\n",
       "111  ['disparos', 'morto', 'crime', 'acionada', 'vi...      1\n",
       "6    ['preso', 'tupã', 'porta', 'relacionamento', '...      1\n",
       "87   ['pm', 'clonada', 'casa', 'filho', 'armas', 'm...      1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset:  105\n",
      "Test dataset:  35\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    news_df['KW'], \n",
    "    news_df['TARGET'], \n",
    "    random_state = 1\n",
    ")\n",
    "\n",
    "print(\"Training dataset: \", X_train.shape[0])\n",
    "print(\"Test dataset: \", X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"['luciene', 'amante', 'pm', 'efetuados', 'homem', 'tiros', 'vista', 'comete', 'vinicius', 'chegou', 'seguida', 'mata', 'esposa', 'albério', 'polícia', 'carro', 'suicídio']\", \"['preso', 'áudios', 'aragarças', 'família', 'tiros', 'jovem', 'suposta', 'pms', 'jeferson', 'troca', 'morreu', 'menino', 'polícia', 'apontam', 'carro']\"]\n"
     ]
    }
   ],
   "source": [
    "print(kw_trainA[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vector = CountVectorizer()\n",
    "training_data = count_vector.fit_transform(X_train)\n",
    "testing_data = count_vector.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 482)\t1\n",
      "  (0, 169)\t1\n",
      "  (0, 342)\t1\n",
      "  (0, 53)\t1\n",
      "  (0, 152)\t1\n",
      "  (0, 513)\t1\n",
      "  (0, 6)\t1\n",
      "  (1, 658)\t1\n",
      "  (1, 414)\t1\n",
      "  (1, 235)\t1\n",
      "  (1, 737)\t1\n",
      "  (1, 691)\t1\n",
      "  (1, 473)\t1\n",
      "  (1, 621)\t1\n",
      "  (1, 56)\t1\n",
      "  (1, 120)\t1\n",
      "  (1, 190)\t1\n",
      "  (1, 344)\t1\n",
      "  (1, 692)\t1\n",
      "  (1, 659)\t1\n",
      "  (1, 649)\t1\n",
      "  (1, 18)\t1\n",
      "  (2, 601)\t1\n",
      "  (2, 665)\t1\n",
      "  (2, 310)\t1\n",
      "  :\t:\n",
      "  (103, 586)\t1\n",
      "  (103, 422)\t1\n",
      "  (103, 289)\t1\n",
      "  (103, 706)\t1\n",
      "  (103, 526)\t1\n",
      "  (103, 666)\t1\n",
      "  (103, 498)\t1\n",
      "  (103, 199)\t1\n",
      "  (103, 692)\t1\n",
      "  (104, 455)\t1\n",
      "  (104, 40)\t1\n",
      "  (104, 275)\t1\n",
      "  (104, 69)\t1\n",
      "  (104, 594)\t1\n",
      "  (104, 718)\t1\n",
      "  (104, 36)\t1\n",
      "  (104, 562)\t1\n",
      "  (104, 614)\t1\n",
      "  (104, 589)\t1\n",
      "  (104, 556)\t1\n",
      "  (104, 300)\t1\n",
      "  (104, 19)\t1\n",
      "  (104, 503)\t1\n",
      "  (104, 190)\t1\n",
      "  (104, 53)\t1\n"
     ]
    }
   ],
   "source": [
    "print(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(training_data, y_train)\n",
    "#clf.fit(news_df['KW'],news_df['TARGET'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0',\n",
       "       '1', '1', '1', '0', '1', '1', '1', '1', '1'], dtype='<U1')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = clf.predict(testing_data)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.9142857142857143\n",
      "Recall score:  0.9142857142857143\n",
      "Precision score:  0.9017316017316018\n",
      "F1 score:  0.9063736263736264\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "print(\"Accuracy score: \", accuracy_score(y_test, predictions))\n",
    "print(\"Recall score: \", recall_score(y_test, predictions, average = 'weighted'))\n",
    "print(\"Precision score: \", precision_score(y_test, predictions, average = 'weighted'))\n",
    "print(\"F1 score: \", f1_score(y_test, predictions, average = 'weighted'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
