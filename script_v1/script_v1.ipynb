{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import collections\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import RSLPStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#realiza a separação das palavras\n",
    "def tokenize(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    sentence = nltk.word_tokenize(sentence)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduz a palavra para o seu sentido \"raiz\"\n",
    "def stemming(sentence):\n",
    "    stemmer = RSLPStemmer()\n",
    "    phrase = []\n",
    "    for word in sentence:\n",
    "        phrase.append(stemmer.stem(word.lower()))\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove palavras que não possuem \"valor\"\n",
    "stopWords = list()\n",
    "df_stopWords = pd.read_csv('stop_words_list.txt')\n",
    "for element in df_stopWords.values:\n",
    "    for word in element:\n",
    "        stopWords.append(word)\n",
    "\n",
    "def removeWords(_words_list_, _stopWordsList_):\n",
    "    #stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "    #stop_words = set(stopwords.words('portuguese'))\n",
    "    _stopWordsList_.extend(['.', ',', '\"', \"'\", '?', '!', ':', ';', '(', ')', '[', ']', '{', '}']) \n",
    "        \n",
    "    _words_ = list()\n",
    "    for word in _words_list_:\n",
    "        if word not in _stopWordsList_:\n",
    "            _words_.append(word)\n",
    "    return _words_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop_words = set(stopwords.words('portuguese'))\n",
    "#stop_words.update(['de','.', ',', '\"', \"'\", '?', '!', ':', ';', '(', ')', '[', ']', '{', '}']) \n",
    "#stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://g1.globo.com/rr/roraima/noticia/2019/02/14/homem-mata-esposa-e-amante-a-tiros-e-comete-suicidio-em-boa-vista.ghtml',\n",
       " 'https://g1.globo.com/am/amazonas/noticia/2019/02/11/homem-e-morto-a-tiros-em-lava-jato-na-zona-sul-de-manaus.ghtml',\n",
       " 'https://g1.globo.com/ac/acre/noticia/2019/02/11/jovem-e-morto-a-tiros-na-frente-da-namorada-em-bairro-de-rio-branco.ghtml']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls = ['https://g1.globo.com/rr/roraima/noticia/2019/02/14/homem-mata-esposa-e-amante-a-tiros-e-comete-suicidio-em-boa-vista.ghtml',\n",
    "        'https://g1.globo.com/am/amazonas/noticia/2019/02/11/homem-e-morto-a-tiros-em-lava-jato-na-zona-sul-de-manaus.ghtml',\n",
    "        'https://g1.globo.com/ac/acre/noticia/2019/02/11/jovem-e-morto-a-tiros-na-frente-da-namorada-em-bairro-de-rio-branco.ghtml'\n",
    "       ]\n",
    "urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><strong><span style=\"color: #3366ff;\">Realiza o soup na mat&eacute;ria do site</span></strong></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = requests.Session()\n",
    "page = sess.request(method='Get', url=urls[0])\n",
    "soup = BeautifulSoup(page.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Homem mata esposa e amante a tiros e comete suicídio em Boa Vista'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = soup.find(class_=\"title\").get_text().strip()\n",
    "title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><strong><span style=\"color: #3366ff;\">Retira do site as frases importantes</span></strong></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O crime foi por volta das 17h no bairro do Estados, zona Norte da capital. Os tiros foram efetuados com uma pistola calibre 380, segundo a PM.',\n",
       " 'De acordo com a PM, durante a tarde Luciene chegou em um carro, estacionou próximo a uma distribuidora e entrou em uma picape em que estava Albério. Os dois saíram. Nesse período, chegou o esposo, que ficou no local.',\n",
       " 'Depois de um tempo, relataram testemunhas à PM, o carro com a mulher e o amante retornou, momento em que o Vinícius disparou contra eles e em seguida se matou.',\n",
       " 'Ainda não se sabe quantos disparos foram efetuados. Luciene e Albério foram assassinados ainda dentro do carro.',\n",
       " 'Conforme um amigo do casal, Vinicius e Luciene estavam juntos há nove anos, e há dois dias haviam formalizado a união.',\n",
       " 'Os corpos foram removidos do local pelo Instituo Médico Legal às 18h30. A PM isolou o local. A perícia da Polícia Civil foi acionada.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = soup.find_all(class_='content-text__container ')\n",
    "phrases = list()\n",
    "for phrase in text:\n",
    "    phrases.append(phrase.get_text().strip())\n",
    "phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><strong><span style=\"color: #3366ff;\">Realiza o tokenize em cada frase</span></strong></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list()\n",
    "wordList = list()\n",
    "for phrase in phrases:\n",
    "    words.append(tokenize(phrase))\n",
    "\n",
    "#realiza o join de todas as palavras em apenas um lista\n",
    "for words_ in words:\n",
    "    for word in words_:\n",
    "        wordList.append(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><strong><span style=\"color: #3366ff;\">Retira as palavra sem importância das frases</span></strong></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['crime',\n",
       " '17h',\n",
       " 'tiros',\n",
       " 'efetuados',\n",
       " 'calibre',\n",
       " '380',\n",
       " 'a',\n",
       " 'pm',\n",
       " 'a',\n",
       " 'pm',\n",
       " 'a',\n",
       " 'luciene',\n",
       " 'a',\n",
       " 'entrou',\n",
       " 'estava',\n",
       " 'albério',\n",
       " 'relataram',\n",
       " 'testemunhas',\n",
       " 'pm',\n",
       " 'a',\n",
       " 'retornou',\n",
       " 'vinícius',\n",
       " 'disparou',\n",
       " 'eles',\n",
       " 'matou',\n",
       " 'quantos',\n",
       " 'disparos',\n",
       " 'efetuados',\n",
       " 'luciene',\n",
       " 'albério',\n",
       " 'assassinados',\n",
       " 'vinicius',\n",
       " 'luciene',\n",
       " 'estavam',\n",
       " 'haviam',\n",
       " 'a',\n",
       " 'corpos',\n",
       " 'removidos',\n",
       " 'instituo',\n",
       " '18h30',\n",
       " 'a',\n",
       " 'pm',\n",
       " 'a',\n",
       " 'acionada']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filteredwordList = removeWords(wordList, stopWords)\n",
    "filteredwordList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><strong><span style=\"color: #3366ff;\">Realiza a redução da palavra</span></strong></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmingWords = stemming(filteredwordList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'crim': 1,\n",
       "         '17h': 1,\n",
       "         'tir': 1,\n",
       "         'efetu': 2,\n",
       "         'calibr': 1,\n",
       "         '380': 1,\n",
       "         'a': 8,\n",
       "         'pm': 4,\n",
       "         'lucien': 3,\n",
       "         'entr': 1,\n",
       "         'est': 2,\n",
       "         'albéri': 2,\n",
       "         'relat': 1,\n",
       "         'testemunh': 1,\n",
       "         'retorn': 1,\n",
       "         'viníc': 1,\n",
       "         'dispar': 2,\n",
       "         'ele': 1,\n",
       "         'mat': 1,\n",
       "         'quant': 1,\n",
       "         'assassin': 1,\n",
       "         'vinic': 1,\n",
       "         'hav': 1,\n",
       "         'corp': 1,\n",
       "         'remov': 1,\n",
       "         'institu': 1,\n",
       "         '18h30': 1,\n",
       "         'acion': 1})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countWords = collections.Counter(stemmingWords)\n",
    "countWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "base = pd.read_csv('census.csv')\n",
    "\n",
    "previsores = base.iloc[:, 0:14].values\n",
    "classe = base.iloc[:, 14].values\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "previsores_treinamento, previsores_teste, classe_treinamento, classe_teste = train_test_split(previsores, classe, test_size=0.15, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classificador = RandomForestClassifier(n_estimators=40, criterion='entropy', random_state=0)\n",
    "classificador.fit(previsores_treinamento, classe_treinamento)\n",
    "previsoes = classificador.predict(previsores_teste)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "precisao = accuracy_score(classe_teste, previsoes)\n",
    "matriz = confusion_matrix(classe_teste, previsoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
