{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificador utilizando Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para Naive Bayes, podemos utilizar duas modalidades de algorítmo:\n",
    "- Multinomial Naive Bayes\n",
    "- Bernoulli Naive Bayes\n",
    "\n",
    "É recomendado que testemos ambas as possibilidades para garantir o melhor encaixe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importe bibliotecas necessárias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O número de sites analisados está igual ao número de resultados! Ótimo!\n"
     ]
    }
   ],
   "source": [
    "fileHandle = open('kw_list_train.txt','r') # esta lista possui as palavras-chave de cada link analisado\n",
    "kw_train = fileHandle.readlines()\n",
    "fileHandle.close()\n",
    "\n",
    "fileHandle = open('target_train.txt','r') # esta lista corresponde aos valores-alvo ordenados de acordo com a lista anterior\n",
    "target_train = fileHandle.readlines()\n",
    "fileHandle.close()\n",
    "\n",
    "# Para confirmar se nossos dados estão alinhados, o comprimento de cada lista deve ser o mesmo:\n",
    "# Número de lista de palavras-chave == numero de resultados 0 ou 1\n",
    "# Entendemos 0 como uma notícia não-pertinente, que não se trata de violência, e 1 como uma notícia sobre o uso\n",
    "# violento de armas de fogo.\n",
    "if (len(kw_train) == len(target_train)):\n",
    "    print(\"O número de sites analisados está igual ao número de resultados! Ótimo!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precisei criar esta função abaixo para rearranjar o documento com a lista de listas de keywords para separar o resultado de cada website. A função resulta em uma lista consultável de 2 dimensões."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['preso', 'áudios', 'aragarças', 'família', 'tiros', 'jovem', 'suposta', 'pms', 'jeferson', 'troca', 'morreu', 'menino', 'polícia', 'apontam', 'carro']\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# Este bloco formata as strings dos arquivos lidos removendo caracteres indesejados.\n",
    "\n",
    "kw_trainA = [] # Preferi criar uma lista vazia para manipular os dados. Caso dê algo errado nossa lista inicial estará à salvo.\n",
    "\n",
    "# Como o resultado esperado é uma lista de listas, sendo a lista secundária uma str a ser analisada pelo NB, faz-se:\n",
    "for line in kw_train:\n",
    "    sublist = []\n",
    "    line = line.split(\",\")\n",
    "    for word in line:\n",
    "        word = word.rstrip()\n",
    "        word = word.strip(\" ' \\\" \\] \\[ \") # tira aspas, colchetes e espaços\n",
    "        sublist.append(word)\n",
    "    sublist = str(sublist)\n",
    "    kw_trainA.append(sublist)\n",
    "\n",
    "targetA = []\n",
    "for line in target_train:\n",
    "    line = line.rstrip()\n",
    "    targetA.append(line)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CRIANDO O DATAFRAME\n",
    "\n",
    "Vamos criar um dataframe. É como se fosse uma tabela do bom e velho Excel e que vai nos dar mais facilidade na manipulação de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'KW': kw_trainA, 'TARGET': targetA} # as informações serão divididas em duas colunas,\n",
    "                                            #cujos valores são as listas formatadas previamente.\n",
    "news_df = pd.DataFrame(data, columns=['KW','TARGET'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KW</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>['provoca', 'foto', 'instagram', 'posta', 'hen...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>['assassinado', 'santos', 'edísio', 'descarta'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>['morto', 'caldas', 'tiros', 'jovem', 'residên...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>['adolescente', 'tráfico', 'araçatuba', 'homem...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>['rosto', 'morto', 'pública', 'tiros', 'idoso'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>['acusado', 'matar', 'suspeito', 'disparo', 'd...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>['arremessar', 'armas', 'seres', 'homens', 'te...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>['disparos', 'morto', 'crime', 'acionada', 'vi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>['preso', 'tupã', 'porta', 'relacionamento', '...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>['pm', 'clonada', 'casa', 'filho', 'armas', 'm...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    KW TARGET\n",
       "136  ['provoca', 'foto', 'instagram', 'posta', 'hen...      0\n",
       "19   ['assassinado', 'santos', 'edísio', 'descarta'...      1\n",
       "75   ['morto', 'caldas', 'tiros', 'jovem', 'residên...      1\n",
       "69   ['adolescente', 'tráfico', 'araçatuba', 'homem...      1\n",
       "27   ['rosto', 'morto', 'pública', 'tiros', 'idoso'...      1\n",
       "62   ['acusado', 'matar', 'suspeito', 'disparo', 'd...      1\n",
       "134  ['arremessar', 'armas', 'seres', 'homens', 'te...      0\n",
       "111  ['disparos', 'morto', 'crime', 'acionada', 'vi...      1\n",
       "6    ['preso', 'tupã', 'porta', 'relacionamento', '...      1\n",
       "87   ['pm', 'clonada', 'casa', 'filho', 'armas', 'm...      1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exibe 10 amostras aleatórias do dataset.\n",
    "news_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para utilizar o próprio conjunto de treinamento para testar a acurácia, utilizaremos a ferramenta train_test_split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset:  105\n",
      "Test dataset:  35\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# a coluna KW será nosso 'X' enquanto a coluna TARGET será nosso 'y'\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    news_df['KW'], \n",
    "    news_df['TARGET'], \n",
    "    random_state = 1 # este random state serve para caso desejemos reproduzir a mesma pseudoaleatoriedade em outro momento\n",
    ")\n",
    "\n",
    "print(\"Training dataset: \", X_train.shape[0]) # o dataset de treinos possui esta dimensão\n",
    "print(\"Test dataset: \", X_test.shape[0]) # e o dataset de teste possui esta dimensão."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creio que a parte mais importante é a vetorização das palavras-chave. O modelo NB não aceita a leitura de caracteres diretamente, sendo então necessária a conversão de uma string de palavras para um vetor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vector = CountVectorizer()\n",
    "training_data = count_vector.fit_transform(X_train) # vetorizaremos tanto o train set\n",
    "testing_data = count_vector.transform(X_test) # quanto o test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 482)\t1\n",
      "  (0, 169)\t1\n",
      "  (0, 342)\t1\n",
      "  (0, 53)\t1\n",
      "  (0, 152)\t1\n",
      "  (0, 513)\t1\n",
      "  (0, 6)\t1\n",
      "  (1, 658)\t1\n",
      "  (1, 414)\t1\n",
      "  (1, 235)\t1\n",
      "  (1, 737)\t1\n",
      "  (1, 691)\t1\n",
      "  (1, 473)\t1\n",
      "  (1, 621)\t1\n",
      "  (1, 56)\t1\n",
      "  (1, 120)\t1\n",
      "  (1, 190)\t1\n",
      "  (1, 344)\t1\n",
      "  (1, 692)\t1\n",
      "  (1, 659)\t1\n",
      "  (1, 649)\t1\n",
      "  (1, 18)\t1\n",
      "  (2, 601)\t1\n",
      "  (2, 665)\t1\n",
      "  (2, 310)\t1\n",
      "  :\t:\n",
      "  (103, 586)\t1\n",
      "  (103, 422)\t1\n",
      "  (103, 289)\t1\n",
      "  (103, 706)\t1\n",
      "  (103, 526)\t1\n",
      "  (103, 666)\t1\n",
      "  (103, 498)\t1\n",
      "  (103, 199)\t1\n",
      "  (103, 692)\t1\n",
      "  (104, 455)\t1\n",
      "  (104, 40)\t1\n",
      "  (104, 275)\t1\n",
      "  (104, 69)\t1\n",
      "  (104, 594)\t1\n",
      "  (104, 718)\t1\n",
      "  (104, 36)\t1\n",
      "  (104, 562)\t1\n",
      "  (104, 614)\t1\n",
      "  (104, 589)\t1\n",
      "  (104, 556)\t1\n",
      "  (104, 300)\t1\n",
      "  (104, 19)\t1\n",
      "  (104, 503)\t1\n",
      "  (104, 190)\t1\n",
      "  (104, 53)\t1\n"
     ]
    }
   ],
   "source": [
    "print(training_data) # é assim que se parecerá o set vetorizado\n",
    "len(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB() # eis então o Multinomial Naive Bayes\n",
    "clf.fit(training_data, y_train) # fit é o comando que recebe os dados de X e y para criar o classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0',\n",
       "       '1', '1', '1', '0', '1', '1', '1', '1', '1'], dtype='<U1')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Após treinado o modelo, a predição é feita com o seguinte comando:\n",
    "\n",
    "predictions = clf.predict(testing_data)\n",
    "predictions # exibe o resultado das predições."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESULTADOS\n",
    "\n",
    "É observado que o resultado está impreciso/viciado pela falta de exemplos negativos. Será necessário voltar à coleta de dados e reaplicar o treinamento no modelo para que este possua mais parâmetros comparativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.9142857142857143\n",
      "Recall score:  0.9142857142857143\n",
      "Precision score:  0.9017316017316018\n",
      "F1 score:  0.9063736263736264\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "print(\"Accuracy score: \", accuracy_score(y_test, predictions))\n",
    "print(\"Recall score: \", recall_score(y_test, predictions, average = 'weighted'))\n",
    "print(\"Precision score: \", precision_score(y_test, predictions, average = 'weighted'))\n",
    "print(\"F1 score: \", f1_score(y_test, predictions, average = 'weighted'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
